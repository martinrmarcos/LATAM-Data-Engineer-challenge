{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importar libreria a usar\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import unicodedata\n",
    "import emoji\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "class tweet_process():\n",
    "\n",
    "    def json_to_df(self, file_name):\n",
    "    ### This function receives the file name and searches the current path for it\n",
    "    ### after that it iterates over all tweets adding them to a list using json_normalize\n",
    "    ### with max_level = 1 to only get one layer deeper into the json file\n",
    "    ### This function could be imporved by changinf the max_level in order to save more information per tweet\n",
    "        current_directory = os.path.dirname(os.path.realpath('__file__')) # Getting the actual path\n",
    "        file_name = file_name\n",
    "        file_path = os.path.join(current_directory, file_name)\n",
    "        normalized_data_list = []\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path) as json_file: # Opening file and iterating over it\n",
    "                for line in json_file:\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        normalized_data_list.append(pd.json_normalize(data, max_level=1))# Using json_normalize to extract the info\n",
    "                    except json.JSONDecodeError as e: # Testing all tweets for structure\n",
    "                        print(f\"Error decoding JSON: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        return pd.concat(normalized_data_list, ignore_index=True) # Retrieveng a DF\n",
    "\n",
    "    def convert_lowercase(self, df):\n",
    "    ### Just a basic function in order to normalize the data by getting all values \n",
    "    ### to lowercase and extracting all accentuation\n",
    "        def strip_accents(s):\n",
    "            return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                            if unicodedata.category(c) != 'Mn')\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "        df.columns = map(strip_accents, df.columns)\n",
    "        df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "        return df\n",
    "\n",
    "    def topX_most_retweeted(self, df, top = 10, retweetcount_column = 'retweetcount'):\n",
    "    ### This function receives the df and retrieves a new df with the most retweeted tweets\n",
    "    ### using the function sort_values\n",
    "    ### This could be improved by making the top ammount variable as shown\n",
    "    ### It could be also improved by receiving an specific year, month date in which to look up\n",
    "        df[retweetcount_column] = pd.to_numeric(df[retweetcount_column])\n",
    "        topX_retweeted_tweets = df.sort_values(by=retweetcount_column, ascending=False).head(top) # using the function sort_values to order the values\n",
    "        return topX_retweeted_tweets\n",
    "\n",
    "    def topX_tweets_per_person(self, df, top = 10, username_column = 'user.username'):\n",
    "    ### This function receives the df and retrieves a new df with the people with the most tweets\n",
    "    ### using a value_counts over the username\n",
    "    ### This could be improved by making the top ammount variable as shown\n",
    "    ### It could be also improved by receiving an specific year, month date in which to look up\n",
    "        return pd.DataFrame(df[username_column].value_counts().head(top))\n",
    "\n",
    "    def topX_tweets_per_day(self, df, top = 10, date_columns = 'date'):\n",
    "    ### This function receives the df and retrieves a new df with the days were \n",
    "    ### there were the most ammount of tweets, using a value_counts over the transformed 'day' value\n",
    "    ### This could be improved by making the top ammount variable as shown\n",
    "    ### It could be also improved by receiving an specific year or month in which to look up\n",
    "        df[date_columns] = pd.to_datetime(df[date_columns])\n",
    "        df['day'] = df['date'].dt.date\n",
    "        return pd.DataFrame(df['day'].value_counts().head(top))\n",
    "\n",
    "    def topX_most_used_hashtags(self, df, top = 10, tweet_column = 'renderedcontent'):\n",
    "    ### This function receives the df and retrieves a new df with the most used hashtags\n",
    "    ### using a value_count() over the hashtags extracted by using the REGEX '#\\w+' and findall\n",
    "    ### This could be improved by making the top ammount variable as shown\n",
    "    ### It could be also improved by receiving an specific year, month date in which to look up\n",
    "        all_text = ' '.join(df[tweet_column]) # Getting al text together\n",
    "        hashtags = re.findall(r'#\\w+', all_text) # gatting all hashtags in all tweets\n",
    "        return pd.DataFrame(pd.Series(hashtags).value_counts().head(top))\n",
    "\n",
    "    def topX_most_used_emoji(self, df, top = 10, tweet_column = 'renderedcontent'):\n",
    "    ### This function receives the df and retrieves a new df with the most used emojis\n",
    "    ### using emoji.UNICODE_EMOJI to find all emojies within all tweets, and sorting them to get the most used\n",
    "    ### This could be improved by making the top ammount variable as shown\n",
    "    ### It could be also improved by receiving an specific year, month date in which to look up\n",
    "        all_text = ' '.join(df[tweet_column])\n",
    "        emojislist = [c for c in all_text if c in emoji.UNICODE_EMOJI['en']] # Usign emoji.UNICODE_EMOJI to find all emojies\n",
    "        top_X_emojis = dict(sorted(Counter(emojislist).items(), key=lambda x: x[1], reverse=True)[:top]) # Sorting out the dictionay that has all used emojies\n",
    "        return pd.DataFrame(list(top_X_emojis.items()), columns=['emoji', 'count'])\n",
    "\n",
    "    def topX_most_influential(self, df, top = 10, retweetcount_column = 'retweetcount', username_column = 'user.username'):\n",
    "    ### This function receives the df and retrieves a new df with the most influential users according to ther retweets\n",
    "    ### using a groupby on retweetcount over username and then reordering them Descending\n",
    "    ### This could be improved by making the top ammount variable as shown\n",
    "    ### It could be also improved by receiving an specific year, month date in which to look up\n",
    "        df[retweetcount_column] = pd.to_numeric(df[retweetcount_column])\n",
    "        user_retweet_counts = df.groupby(username_column)[retweetcount_column].sum() # using a groupby on retweetcount over username and then reordering them Descending\n",
    "        return pd.DataFrame(user_retweet_counts.sort_values(ascending=False).head(top))\n",
    "\n",
    "################## The following function can only be used if the postgres docker steps were completed\n",
    "################## Please check readme file\n",
    "\n",
    "\n",
    "    def upload_to_sql(self, df, columns_to_sql, table_name):\n",
    "    ### This function will upload certain df with its seelcted columns into a selected table on the created DB\n",
    "    ### Using sqlalchemy we can acces a DB and perform changes to it\n",
    "        username = 'postgres'\n",
    "        password = 'Latam2023'\n",
    "        host = '0.0.0.0'  \n",
    "        port = '5432'  \n",
    "        database_name = 'LATAMDB'\n",
    "        engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database_name}') # Creating an engine with the data from the recently created DB\n",
    "        connection = engine.connect()\n",
    "        return df[columns_to_sql].to_sql(table_name, engine, if_exists='replace', index=False) # Publishing the selected values the SQL DB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
